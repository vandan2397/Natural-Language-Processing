{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9206fc",
   "metadata": {},
   "source": [
    "<h3>Import Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e0c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install lxml (parser)\n",
    "# install html5lib (parser)\n",
    "\n",
    "# install beautiful soup for webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# install requests to connect to urls\n",
    "import requests\n",
    "\n",
    "# install pandas for analysis\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f79e118",
   "metadata": {},
   "source": [
    "<h3>Web Scraping Class</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605978e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraping():\n",
    "    \n",
    "    \n",
    "    # Function to get links of all pages\n",
    "    def get_links():\n",
    "        \n",
    "        # Links of all pages\n",
    "        links = []\n",
    "        \n",
    "        for i in range(1,238):\n",
    "            links.append(\"https://www.consumeraffairs.com/online/amazon.html?page=\"+str(i))\n",
    "        \n",
    "        return links\n",
    "\n",
    "\n",
    "    # Function to get data from all pages\n",
    "    def Scraping(links):\n",
    "        \n",
    "\n",
    "        # list for rating\n",
    "        rating_list = []\n",
    "\n",
    "\n",
    "        # list for review\n",
    "        review_list = []\n",
    "\n",
    "        for i in links:\n",
    "            source = requests.get(i).text\n",
    "            soup = BeautifulSoup(source,'lxml')\n",
    "        \n",
    "            # Extracting reviews by customers\n",
    "            for article in soup.find_all('div',class_='rvw js-rvw'):\n",
    "                review = article.find('div', class_='rvw-bd')\n",
    "                review_list.append(review.text)\n",
    "            \n",
    "            # Extracting ratings by customers\n",
    "            for article1 in soup.find_all('div',class_='rvw__hdr-stat'):\n",
    "                #ratings\n",
    "                rating_list.append(article1.find('meta',itemprop='ratingValue')['content'])\n",
    "\n",
    "        \n",
    "        # Creaing dataframes of both list\n",
    "        rating_df = pd.DataFrame(rating_list)\n",
    "        review_df = pd.DataFrame(review_list)\n",
    "        \n",
    "        # Combining Dataframe\n",
    "        data = pd.concat([rating_df,review_df],axis=1)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    # Function for preprocessing of data\n",
    "    def Preprocess(data):\n",
    "        \n",
    "        # drop insignificant column\n",
    "        data.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "        # Rename columns\n",
    "        data.columns = ['Reviews','Ratings']\n",
    "        \n",
    "        \n",
    "        #manipulating values using lambda function\n",
    "        data['Reviews_1'] = data['Reviews'].apply(lambda x: x.replace('Original review:',''))\n",
    "        \n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2011','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2012','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2013','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2014','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2015','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2016','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2017','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2018','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2019','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2020','',1))\n",
    "        data['Reviews_1'] = data['Reviews_1'].apply(lambda x: x.replace('2021','',1))\n",
    "        \n",
    "        \n",
    "        # Extracting data which has ratings along with review\n",
    "        data = data.iloc[0:6621,:]\n",
    "        \n",
    "        # Dropping old Reviews column\n",
    "        data.drop('Reviews',axis=1,inplace=True)\n",
    "        \n",
    "    \n",
    "        # labelling ratings\n",
    "\n",
    "        # Ratings to label\n",
    "        def tenure_lab(data) :\n",
    "            if data[\"Ratings\"] <= 3 :\n",
    "                return \"Bad\"\n",
    "            elif (data[\"Ratings\"] >= 4) :\n",
    "                return \"Good\"\n",
    "         \n",
    "        data[\"Ratings\"] = data.apply(lambda data:tenure_lab(data), axis = 1)\n",
    "        \n",
    "        data.columns = ['Ratings','Reviews']\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8547d",
   "metadata": {},
   "source": [
    "<h3>Driver Code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "webscrap = WebScraping()\n",
    "\n",
    "# calling getlinks method\n",
    "links = webscrap.get_links()\n",
    "\n",
    "# calling Scraping function\n",
    "data = webscrap.Scraping(links)\n",
    "\n",
    "# calling preprocess method\n",
    "file = webscrap.Preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Data\n",
    "\n",
    "file.to_csv('Data/Amazon_customer_Reviews.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
